{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83449621-e3f7-4202-a836-645fe1bbd5c5",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329484d-db1b-48fe-b7a0-b035ad5356bb",
   "metadata": {},
   "source": [
    "RL algorithms SARSA and Q-learning have callback hooks for episode number, begin, end, and env. step.   To create a callback, override one of the callback functions in the child class MyCallbacks.  Or, you can use the add_to decorator to define the override outside of the class definition. For example, print the episode number every 1000 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "787ce4d3-e2b6-459f-94a6-ae4201fa091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1661/10000 [00:00<00:01, 8314.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " episode= 0\n",
      " episode= 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3302/10000 [00:00<00:00, 8044.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " episode= 2000\n",
      " episode= 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4911/10000 [00:00<00:00, 7923.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " episode= 4000\n",
      " episode= 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 7295/10000 [00:00<00:00, 7878.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " episode= 6000\n",
      " episode= 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8843/10000 [00:01<00:00, 7328.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " episode= 8000\n",
      " episode= 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 1.31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from bettermdptools.utils.decorators import add_to\n",
    "from bettermdptools.utils.callbacks import MyCallbacks\n",
    "from bettermdptools.algorithms.rl import RL\n",
    "from bettermdptools.envs.blackjack_wrapper import BlackjackWrapper\n",
    "\n",
    "base_env = gym.make('Blackjack-v1', render_mode=None)\n",
    "blackjack = BlackjackWrapper(base_env)\n",
    "\n",
    "@add_to(MyCallbacks)\n",
    "def on_episode(self, caller, episode):\n",
    "    if episode % 1000 == 0:\n",
    "    \tprint(\" episode=\", episode)\n",
    "\n",
    "# Q-learning\n",
    "Q, V, pi, Q_track, pi_track, rewards = RL(blackjack).q_learning()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bettermdptools",
   "language": "python",
   "name": "bettermdptools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
